# ğŸš SAM-HQ Eelgrass â€” High-Resolution Eelgrass Segmentation

This repository contains a customized training and evaluation pipeline for **SAM-HQ (Segment Anything Model â€“ High Quality)** applied to **high-resolution drone imagery** of West Coast eelgrass meadows (AK / BC / WA / OR).  
The project supports **RGB**, **index channels**, **GLCM texture**, and multi-channel training.

---

## ğŸ“‚ Repository Structure

```text
sam-hq-eelgrass/
â”‚
â”œâ”€â”€ train/                          # Training scripts, configs, logs
â”‚   â”œâ”€â”€ dataset/                    # Custom eelgrass dataset loader
â”‚   â”œâ”€â”€ transforms/                 # Data augmentation
â”‚   â”œâ”€â”€ work_dirs/                  # All logs (per site, per model)
â”‚   â””â”€â”€ train_rgb.py                # Example RGB training script
â”‚
â”œâ”€â”€ eval/                           # Evaluation tools
â”‚   â”œâ”€â”€ eval_single.py              
â”‚   â””â”€â”€ metrics/                    # IoU, Dice, boundary IoU, etc.
â”‚
â”œâ”€â”€ utils/                          # Helper modules
â”‚   â”œâ”€â”€ tiling/                     
â”‚   â””â”€â”€ image_utils.py
â”‚
â”œâ”€â”€ pretrained_checkpoint/          # (Ignored) Put SAM-HQ weights here
â”‚   â””â”€â”€ sam_hq_vit_l.pth  (NOT included)
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ“¦ Installation

Tested on:

- Python 3.8â€“3.10  
- PyTorch 2.1+  
- CUDA 11.8 / 12.x  

Install:

```bash
conda create -n samhq python=3.10 -y
conda activate samhq
pip install -r requirements.txt
```

Install SAM-HQ:

```bash
pip install git+https://github.com/SysCV/sam-hq.git
```

---

## ğŸ“¥ Pretrained Weights

SAM-HQ-L (~1.2GB) is **not included** in this repo.

Place it here after downloading:

```
pretrained_checkpoint/sam_hq_vit_l.pth
```

Add your download link here:

ğŸ”— `<your-weight-link>`

---

## ğŸ“ Dataset Structure

```text
data/
â”œâ”€â”€ BC/
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ image/
â”‚   â”‚   â””â”€â”€ index/
â”‚   â”œâ”€â”€ valid/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ WA/
â”œâ”€â”€ OR/
â””â”€â”€ AK/
```

Tile naming format:

```
<site>_<region>_<year>_rowXX_colYY.png
```

Example:

```
BH_WA_19_row10_col50.png
```

---

## ğŸš€ Training

Basic RGB training:

```bash
python train/train.py \
    --data-root /path/to/data \
    --output ./train/work_dirs/rgb_run1 \
    --checkpoint ./pretrained_checkpoint/sam_hq_vit_l.pth \
    --epochs 30
```

Multi-channel example:

```bash
python train/train_multichannel.py \
    --modalities rgb index \
    --data-root /path/to/data
```

Logs saved in:

```
train/work_dirs/
```

---

## ğŸ§ª Evaluation

```bash
python eval/eval_single.py \
    --data-root /path/to/data \
    --checkpoint ./train/work_dirs/rgb_run1/best_model.pth \
    --output ./eval/results
```

Metrics include:

- IoU  
- Dice  
- Precision / Recall  
- Boundary IoU  
- Hausdorff Distance  

---

## ğŸ“Š Tiling Pipeline (512Ã—512, 30% Overlap)

Tiling script:

```
utils/tiling/tile_pair.py
```

Outputs:

```
image/<basename>/...
index/<basename>/...
manifest/<basename>.csv
```

---

## ğŸ“ TODO

- [ ] Add multi-GPU (DDP) training  
- [ ] Upload pre-trained eelgrass models  
- [ ] Add visualization notebook  
- [ ] Add dataset splitter scripts  
- [ ] Publish evaluation benchmark  

---

## ğŸ“„ License

MIT License.  
Please cite this repository if used in published work.

